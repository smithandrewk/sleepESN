{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.io import read_raw_edf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "def check_activity_equal(fileindex):\n",
    "    csv_filepath = f'data/{fileindex}.csv'\n",
    "    raw = read_edf_by_fileindex(fileindex)\n",
    "    data = raw.get_data(picks='Activity')[0]\n",
    "    computed_activity_means_from_edf = []\n",
    "    for i in range(0,len(data),5000):\n",
    "        computed_activity_means_from_edf.append(data[i:i+5000].mean())\n",
    "    del data\n",
    "    true_activity_means_from_csv = pd.read_csv(csv_filepath)['Activity (Mean, 10s)'].to_numpy()\n",
    "    if(len(computed_activity_means_from_edf) != len(true_activity_means_from_csv)):\n",
    "        print('Activity vector lengths not equal!')\n",
    "        return False,computed_activity_means_from_edf,true_activity_means_from_csv\n",
    "    if(not np.allclose(computed_activity_means_from_edf,true_activity_means_from_csv,atol=.001)):\n",
    "        print('Activity vectors not equal within atol of .001')\n",
    "        return False,computed_activity_means_from_edf,true_activity_means_from_csv\n",
    "    return True,computed_activity_means_from_edf,true_activity_means_from_csv\n",
    "def check_emg_equal(fileindex):\n",
    "    csv_filepath = f'data/{fileindex}.csv'\n",
    "    raw = read_edf_by_fileindex(fileindex)\n",
    "    data = raw.get_data(picks='EMG')[0]\n",
    "    computed_emg_means_from_edf = []\n",
    "    for i in range(0,len(data),5000):\n",
    "        computed_emg_means_from_edf.append(data[i:i+5000].mean())\n",
    "    del data\n",
    "    true_emg_means_from_csv = pd.read_csv(csv_filepath)['EEG 2 (Mean, 10s)'].to_numpy()/1000000\n",
    "    if(len(computed_emg_means_from_edf) != len(true_emg_means_from_csv)):\n",
    "        print('EMG vector lengths not equal!')\n",
    "        return False,computed_emg_means_from_edf,true_emg_means_from_csv\n",
    "    if(not np.allclose(computed_emg_means_from_edf,true_emg_means_from_csv,atol=.01)):\n",
    "        print('EMG vectors not equal within atol of .001')\n",
    "        return False,computed_emg_means_from_edf,true_emg_means_from_csv\n",
    "    return True,computed_emg_means_from_edf,true_emg_means_from_csv\n",
    "def read_edf_by_fileindex(fileindex):\n",
    "    filepath = f'data/{fileindex}.edf'\n",
    "    raw = read_raw_edf(filepath,verbose=False)\n",
    "    raw.rename_channels({'EEG 1':'EEG','EEG 2':'EMG'})\n",
    "    raw.set_channel_types({'Activity':'misc',\n",
    "                        'EEG':'eeg',\n",
    "                        'EMG':'emg',\n",
    "                        'HD BattVoltage':'misc',\n",
    "                        'On Time':'misc',\n",
    "                        'Signal Strength':'misc',\n",
    "                        'Temperature':'misc'})\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    activity,_,_ = check_activity_equal(i)\n",
    "    emg,_,_ = check_emg_equal(i)\n",
    "    print(i,activity,emg)\n",
    "\n",
    "\"\"\"\n",
    "    here we check whether files are aligned via proxy activity signals. for each csv file receieved from med school, there are computed...\n",
    "    only fileindex 14 returns false,\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq,a,b = check_activity_equal(14)\n",
    "largest = 0\n",
    "largest_index = -1\n",
    "for i,(x,y) in enumerate(zip(a,b)):\n",
    "    if(abs(x-y)>largest):\n",
    "        largest = abs(x-y)\n",
    "        largest_index = i\n",
    "        print(largest)\n",
    "largest\n",
    "largest_index\n",
    "plt.plot(a[largest_index-10:largest_index+10])\n",
    "plt.plot(b[largest_index-10:largest_index+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format X,Y\n",
    "X = read_edf_by_fileindex(0).get_data(picks='EEG')\n",
    "Y = pd.read_csv('data/0.csv')['label']\n",
    "Y[Y=='P'] = .005\n",
    "Y[Y=='S'] = .003\n",
    "Y[Y=='W'] = .0045\n",
    "y = []\n",
    "for label in Y:\n",
    "    y.append([label]*5000)\n",
    "y = np.array(y).flatten()\n",
    "# y = pd.Categorical(y).codes\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame([X[:4000000][::20],y[:4000000][::20]],index=['X','label']).T\n",
    "fig = px.line(data_frame=plot_df,y=['X','label'])\n",
    "fig.update_layout(xaxis=dict(rangeslider=dict(visible=True),\n",
    "                             type=\"linear\"))\n",
    "fig['layout']['xaxis'].update(range=[0,2250])\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = read_edf_by_fileindex(0).get_data(picks='EEG').T\n",
    "Y = pd.read_csv('data/0.csv')['label']\n",
    "y = pd.Categorical(Y).codes\n",
    "\n",
    "# Use this class to standardize the values of the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "print(X.mean(),X.var())\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "print(scaler.mean_)\n",
    "print(scaler.var_)\n",
    "X = scaler.transform(X)\n",
    "print(X.mean(),X.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_win = []\n",
    "for i in range(0,len(X),5000):\n",
    "    X_win.append(X[i:i+5000])\n",
    "X_win = np.array(X_win).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this class to create a multilayer perceptron (MLP) classifier.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512,),activation='relu',solver='adam',verbose=True,validation_fraction=.2,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(np_Xs_win,np_Ys_win,test_size=.2,random_state=42,stratify=np_Ys_win)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=.2,random_state=42,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "BATCH_SIZE=64\n",
    "EPOCHS=512\n",
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='relu',input_shape=(X_train.shape[-1],)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "            metrics=[\n",
    "    keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc')\n",
    "])\n",
    "baseline_history = model.fit(\n",
    "X_train,\n",
    "tf.one_hot(y_train, 3),\n",
    "batch_size=BATCH_SIZE,\n",
    "epochs=EPOCHS,\n",
    "validation_data=(X_val, tf.one_hot(y_val, depth=3)),\n",
    "callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "    f\"best_model.h5\", save_best_only=True, monitor=\"val_loss\",verbose=1\n",
    "),\n",
    "keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "),\n",
    "keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1,mode='min',restore_best_weights=True),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in baseline_history.history:\n",
    "    print(key)\n",
    "plt.plot(baseline_history.history['categorical_accuracy'])\n",
    "baseline_results = model.evaluate(X_test, tf.one_hot(y_test,depth=3),\n",
    "                                    batch_size=64, verbose=0)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_win = []\n",
    "ys = []\n",
    "for i in range(10):\n",
    "    X = read_edf_by_fileindex(i).get_data(picks='EEG').T\n",
    "    Y = pd.read_csv(f'data/{i}.csv')['label']\n",
    "    y = pd.Categorical(Y).codes\n",
    "    ys.append(y)\n",
    "    del Y\n",
    "    # Use this class to standardize the values of the features.\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    print(X.mean(),X.var())\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    print(scaler.mean_)\n",
    "    print(scaler.var_)\n",
    "    X = scaler.transform(X)\n",
    "    print(X.mean(),X.var())\n",
    "    X_win = []\n",
    "    for i in range(0,len(X),5000):\n",
    "        X_win.append(X[i:i+5000])\n",
    "    X_win = np.array(X_win).squeeze()\n",
    "    Xs_win.append(X_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = Xs_win[0]\n",
    "for i in range(1,10):\n",
    "    Xs = np.concatenate([Xs,Xs_win[i]])\n",
    "del Xs_win\n",
    "Ys = ys[0]\n",
    "for i in range(1,10):\n",
    "    Ys = np.concatenate([Ys,ys[i]])\n",
    "del ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this class to create a multilayer perceptron (MLP) classifier.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512,),activation='relu',solver='adam',verbose=True,validation_fraction=.2,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(Xs,Ys,test_size=.2,random_state=42,stratify=Ys)\n",
    "del Xs\n",
    "del Ys\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=.2,random_state=42,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "clf.fit(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
